# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## ğŸ’¬ Canvas Chat System - How It Works

**Current Status:** âœ… **WORKING** - Voice input + backend conversation API fully integrated

### Architecture Overview

The chat system uses **Canvas** (not UIKit) for rendering messages in VR:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Canvas Chat System (1024x1024 texture)    â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ [User message - blue bubble]       â”‚    â”‚
â”‚  â”‚                  [Assistant - gray]â”‚    â”‚
â”‚  â”‚ [User message - blue bubble]       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚ Placeholder â”‚  ğŸ¤  â”‚ â† 3D invisible     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜    sphere (0.05m)  â”‚
â”‚     "Listening..." â† Status text           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Files

**Frontend:**
- `src/canvas-chat-system.ts` - Main chat system (Canvas rendering, voice, backend API)
- `src/canvas-chat-interaction.ts` - 3D mic button interaction (IWSDK ECS)
- `src/services/gemini-audio-service.ts` - Voice recording + Gemini transcription
- `src/services/audio-feedback.ts` - Sound effects (beeps)
- `src/live-code/client.ts` - WebSocket client (receives tool progress from backend)

**Backend:**
- `backend/src/orchestrator/conversation-orchestrator.ts` - Main AI orchestrator
- `backend/src/websocket/live-code-server.ts` - Broadcasts tool progress events
- `backend/src/services/session-store.ts` - SQLite session persistence

### Voice Input Flow (Push-to-Talk)

1. **User presses mic button** (3D sphere)
   - `CanvasChatInteractionSystem` detects `Pressed` tag
   - Calls `canvasChatSystem.startRecording()`
   - ğŸ”Š Beep sound (1kHz)
   - Canvas shows: "Listening..."
   - MediaRecorder starts capturing audio

2. **User speaks** (while holding button)
   - Audio recorded in WebM format

3. **User releases button**
   - `CanvasChatInteractionSystem` detects `Pressed` removed
   - Calls `canvasChatSystem.stopRecording()`
   - ğŸ”Š Beep sound (600Hz)
   - Canvas shows: "Transcribing..."
   - Audio â†’ base64 â†’ POST to Gemini API
   - **1-2 seconds** â†’ transcribed text received

4. **Send to backend**
   - Canvas shows: "Sending..."
   - POST `/api/conversation` with `{ message, sessionId }`
   - Backend orchestrator processes request

5. **Backend processing** (WebSocket events)
   - `agent_thinking` â†’ Canvas shows: "First I'll read the file..."
   - `tool_use_start` â†’ Canvas shows: "Using Write..."
   - `tool_use_complete` â†’ Canvas shows: "âœ“ Write complete" (2s)
   - File changes â†’ WebSocket `load_file` â†’ 3D object appears

6. **Response received**
   - Canvas shows assistant message
   - ğŸ”Š Success beeps (ascending)
   - Status cleared

### 3D Mic Button (Invisible Sphere)

The mic button is a **semi-transparent 3D sphere** positioned over the Canvas mic icon:

```typescript
// Position calculation (canvas-chat-system.ts:143-150)
const offsetX = (944 / 1024 - 0.5) * 2;  // Canvas button X
const offsetY = -(924 / 1024 - 0.5) * 2; // Canvas button Y (inverted)

micButtonMesh.position.set(
  panelPosition.x + offsetX,  // Right side of panel
  panelPosition.y + offsetY,  // Bottom of panel
  panelPosition.z + 0.05      // Slightly in front
);
```

**Why 3D sphere instead of Canvas hit detection?**
- IWSDK Pressed/Hovered tags work automatically
- No need to convert raycast hit â†’ Canvas coordinates
- Same pattern as Robot system (reliable)

### Status Indicators

**Visual (Canvas text below mic button):**
- "Listening..." (blue) - Recording
- "Transcribing..." (blue, animated dots) - Speech-to-text
- "Sending..." (blue, animated dots) - POST to backend
- "Using Write..." (blue) - Agent using tool (from WebSocket)
- "âœ“ Write complete" (gray, 2s timeout)
- Errors: "Recording failed", "Could not transcribe", etc.

**Audio (Web Audio API):**
- ğŸ”Š High beep (1kHz, 80ms) - Recording start
- ğŸ”Š Low beep (600Hz, 120ms) - Recording stop
- ğŸ”Š 3 ascending beeps - Success
- ğŸ”Š 3 descending beeps - Error

### WebSocket Events (Backend â†’ Frontend)

LiveCodeClient (`src/live-code/client.ts`) forwards to Canvas chat:

```typescript
case 'tool_use_start':
  canvasChat.showToolProgress(toolName, 'starting');
  // Shows: "Using Write..."

case 'tool_use_complete':
  canvasChat.showToolProgress(toolName, 'completed');
  // Shows: "âœ“ Write complete" (2s)

case 'agent_thinking':
  canvasChat.showThinkingMessage(text);
  // Shows: "First I'll read the file..." (truncated to 50 chars)
```

### Session Management

Sessions persist in SQLite (`backend/data/sessions.db`):

```typescript
// Get or create session ID (canvas-chat-system.ts:665-672)
let sessionId = localStorage.getItem('vr_creator_session_id');
if (!sessionId) {
  sessionId = `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  localStorage.setItem('vr_creator_session_id', sessionId);
}
```

Each request to `/api/conversation` includes sessionId â†’ backend loads history â†’ context preserved.

### Debugging Tips

**Check Canvas Chat is initialized:**
```javascript
window.__CANVAS_CHAT__  // Should be CanvasChatSystem instance
```

**Check mic button entity:**
```javascript
// Should have Interactable + MicButton components
```

**Check WebSocket connection:**
```javascript
// Backend logs show:
// "ğŸ“¡ WebSocket client connected"
// "Message broadcast to clients"
```

**Check session:**
```bash
sqlite3 backend/data/sessions.db "SELECT sessionId, json_array_length(messages) FROM sessions;"
```

**Check voice service:**
```javascript
window.__CANVAS_CHAT__.voiceService.isSupported()  // Should be true
```

**Common issues:**
- No audio permission â†’ Check browser console for MediaRecorder errors
- No Gemini API key â†’ Check `.env` has `VITE_GEMINI_API_KEY`
- Status not showing â†’ Check LiveCodeClient is forwarding to `__CANVAS_CHAT__`
- Mic button not clickable â†’ Check entity has `Interactable` + `MicButton` components

---

## âŒ DEPRECATED: UIKit Input (Ğ½Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ)

**ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°:** ĞĞµ Ğ¼Ğ¾Ğ¶ĞµĞ¼ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ¿Ñ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ Ğ¸Ğ· UIKit Input Ğ² VR

**ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°:** ĞĞµ Ğ¼Ğ¾Ğ¶ĞµĞ¼ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ¿Ñ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ Ğ¸Ğ· UIKit Input Ğ² VR

**Ğ§Ñ‚Ğ¾ Ğ¿Ñ€Ğ¾Ğ±Ğ¾Ğ²Ğ°Ğ»Ğ¸:**
- âŒ `messageInput.value` - undefined
- âŒ `messageInput.properties.value` - Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Proxy Ğ¾Ğ±ÑŠĞµĞºÑ‚, Ğ½Ğµ ÑÑ‚Ñ€Ğ¾ĞºÑƒ
- âŒ `messageInput.properties.value.value` - Ğ½Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ `.trim()`
- âŒ Polling ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ frame - Ğ½Ğµ Ğ²Ğ¸Ğ´Ğ¸Ñ‚ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ
- âŒ propertyChangedSignal.subscribe() - Ğ½Ğµ ÑÑ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚
- âŒ Event listeners (focus, blur, input) - Ğ½Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚ Ğ² VR

**Ğ§Ñ‚Ğ¾ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ¾ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ (Ğ¿Ğ¾ Ñ‚Ğ¸Ğ¿Ğ°Ğ¼):**
- âœ… `Input.currentSignal.value` - ReadonlySignal<string>
- âœ… `Input.element.value` - HTMLInputElement Ğ½Ğ°Ğ¿Ñ€ÑĞ¼ÑƒÑ
- âœ… `Input.element.addEventListener('keydown')` - ÑĞ»ÑƒÑˆĞ°Ñ‚ÑŒ Enter

**Ğ¢Ğ¸Ğ¿Ñ‹ Ğ¸Ğ· `@pmndrs/uikit/dist/components/input.d.ts`:**
```typescript
export declare class Input {
    readonly element: HTMLInputElement | HTMLTextAreaElement;
    readonly currentSignal: ReadonlySignal<string>;
    readonly hasFocus: Signal<boolean>;
}
```

**ĞÑƒĞ¶Ğ½Ğ¾:**
1. ĞŸÑ€Ğ¾Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ `currentSignal.value` Ğ² VR
2. ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ»Ğ¸ `element.addEventListener('keydown')`
3. Ğ•ÑĞ»Ğ¸ Ğ½Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ - Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ±Ğ°Ğ³ Ğ² IWSDK Ğ¸Ğ»Ğ¸ Ğ½ÑƒĞ¶ĞµĞ½ Ğ´Ñ€ÑƒĞ³Ğ¾Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´

**Ğ¤Ğ°Ğ¹Ğ»Ñ‹:**
- `src/panel.ts:94-144` - Ñ‚ĞµĞºÑƒÑ‰Ğ°Ñ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚ĞºĞ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Input
- `node_modules/@pmndrs/uikit/dist/components/input.d.ts` - Ñ‚Ğ¸Ğ¿Ñ‹

---

## ğŸ§ª UI Dynamic Chat Test Results (2025-12-05)

**Ğ¦ĞµĞ»ÑŒ:** ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ/ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ñ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ² UIKit Ğ¿Ğ°Ğ½ĞµĞ»ÑŒ

**Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚:** âœ… **Ğ ĞĞ‘ĞĞ¢ĞĞ•Ğ¢!**

### ĞŸÑ€Ğ¾Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸:

| Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ | Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ | API |
|---------|--------|-----|
| Ğ”Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ñ‚ĞµĞºÑÑ‚Ğ° | âœ… Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ | `container.add(new UIKit.Text({...}))` |
| Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² | âœ… Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ | `container.remove(element)` |
| ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ CSS ĞºĞ»Ğ°ÑÑĞ¾Ğ² | âœ… Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ | `element.classList.add('class-name')` |
| Ğ”Ğ¾ÑÑ‚ÑƒĞ¿ Ğº document | âœ… Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ | `window.__PANEL_DOCUMENT__` |

### Ğ’Ñ‹Ğ²Ğ¾Ğ´Ñ‹:

1. **UIKit Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ UI** - Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑÑ‚ÑŒ/ÑƒĞ´Ğ°Ğ»ÑÑ‚ÑŒ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ² runtime
2. **Ğ“Ğ¾Ñ‚Ğ¾Ğ² Ğº Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ñ‡Ğ°Ñ‚Ğ°** - backend Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· WebSocket, frontend Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ¸Ñ… Ğ² Ğ¿Ğ°Ğ½ĞµĞ»ÑŒ
3. **Ğ¡Ñ‚Ğ¸Ğ»Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸** - `classList.add()` Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ÑÑ Ğº Ğ½Ğ¾Ğ²Ñ‹Ğ¼ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼

### Ğ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ ÑˆĞ°Ğ³Ğ¸ Ğ´Ğ»Ñ Ñ‡Ğ°Ñ‚Ğ°:

- [ ] Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ WebSocket action `update_chat` Ğ² `types.ts`
- [ ] Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ğ² `client.ts`
- [ ] Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ ChatSystem Ğ´Ğ»Ñ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸ÑĞ¼Ğ¸
- [ ] Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ°Ğ²Ñ‚Ğ¾ÑĞºÑ€Ğ¾Ğ»Ğ»Ğ¸Ğ½Ğ³ Ğº Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ¼Ñƒ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ
- [ ] Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ backend conversation API

---

## ğŸ”¬ Performance Testing Results (2025-12-05)

**ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°:** Multi-agent Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ñ ÑÑƒĞ±Ğ°Ğ³ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸ ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ¼ĞµĞ´Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ (40+ ÑĞµĞºÑƒĞ½Ğ´ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡)

**Ğ ĞµÑˆĞµĞ½Ğ¸Ğµ:** Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ direct orchestrator Ğ±ĞµĞ· ÑÑƒĞ±Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²

**Ğ’ĞµÑ‚ĞºĞ°:** `experiment/direct-orchestrator-no-subagents`

### âœ… Ğ”Ğ¾ÑÑ‚Ğ¸Ğ³Ğ½ÑƒÑ‚Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹:

| Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ° | Multi-agent | Direct | Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ | Tool calls |
|--------|-------------|--------|-----------|------------|
| ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ¾Ğ±ÑŠĞµĞºÑ‚ (ĞºÑƒĞ±/ÑÑ„ĞµÑ€Ğ°) | ~40s | **11-14s** | **3x Ğ±Ñ‹ÑÑ‚Ñ€ĞµĞµ** | 1 |
| Ğ¡Ğ¾Ğ»Ğ½ĞµÑ‡Ğ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° (126 ÑÑ‚Ñ€Ğ¾Ğº) | N/A | **30.8s** | - | 1 |
| Ğ¢ĞµÑ‚Ñ€Ğ¸Ñ VR (593 ÑÑ‚Ñ€Ğ¾ĞºĞ¸) | N/A | **76.8s** | - | 1 |
| Ğ ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºĞ¾Ğ´Ğ° | N/A | **19-50s** | - | 3-5 |
| ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° ÑÑ†ĞµĞ½Ñ‹ | N/A | **8s** | - | 1 |

**ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ:**
- âœ… **3x ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ** Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡
- âœ… **1 tool call** Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ (Ğ²Ğ¼ĞµÑÑ‚Ğ¾ 5+ Ğ² multi-agent)
- âœ… **ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿ÑƒÑ‚Ğ¸** (src/generated/) Ñ‡ĞµÑ€ĞµĞ· options.cwd
- âœ… **ĞŸĞ¾Ğ»Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹** DistanceGrabbable Ñ MovementMode
- âœ… **Hot reload fix** - ÑÑ‚Ğ°Ñ€Ñ‹Ğµ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ñ‹ ÑƒĞ´Ğ°Ğ»ÑÑÑ‚ÑÑ Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğ¸

### Ğ§Ñ‚Ğ¾ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ»Ğ¸:

**ĞšĞ°Ğº Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ñ‚ĞµÑÑ‚:**

```bash
# Terminal 1: Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ backend Ñ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼
npm run backend

# Terminal 2: ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ¸ Ğ·Ğ°Ğ¼ĞµÑ€Ğ¸Ñ‚ÑŒ Ğ²Ñ€ĞµĞ¼Ñ
time curl -X POST http://localhost:3001/api/conversation \
  -H "Content-Type: application/json" \
  -d '{
    "message": "ÑĞ¾Ğ·Ğ´Ğ°Ğ¹ ĞºÑ€Ğ°ÑĞ½ÑƒÑ ÑÑ„ĞµÑ€Ñƒ",
    "sessionId": "test_perf_$(date +%s)"
  }'
```

**ĞšĞ°Ğº Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹:**

```bash
# 1. ĞŸĞ¾ÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ trace Ñ„Ğ°Ğ¹Ğ»
ls -lt logs/conversation-traces/ | head -2

# 2. ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ metadata (Ğ²Ñ€ĞµĞ¼Ñ, Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹, tools)
cat logs/conversation-traces/conversation-*.json | jq '.metadata'

# 3. ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ñ„Ğ»Ğ¾Ñƒ Ğ²ÑĞµÑ… ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ñ Ñ‚Ğ°Ğ¹Ğ¼Ğ¸Ğ½Ğ³Ğ°Ğ¼Ğ¸
cat logs/conversation-traces/conversation-*.json | jq -r '.trace[] | "\(.timestamp) | \(.message.type // "unknown")"'

# 4. ĞŸĞ¾ÑÑ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹
cat logs/conversation-traces/conversation-*.json | jq '.trace | length'

# 5. ĞĞ°Ğ¹Ñ‚Ğ¸ Ğ²ÑĞµ tool calls
cat logs/conversation-traces/conversation-*.json | jq '[.trace[].message.message.content[]? | select(.type? == "tool_use") | .name] | unique'
```

**ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹:**

1. **Double Write** - code-generator Ğ¿Ğ¸ÑˆĞµÑ‚ Ñ„Ğ°Ğ¹Ğ» Ğ´Ğ²Ğ°Ğ¶Ğ´Ñ‹ (ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ° ÑĞ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚, Ğ¿Ğ¾Ñ‚Ğ¾Ğ¼ Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµÑ‚)
2. **Unnecessary Read** - Ğ°Ğ³ĞµĞ½Ñ‚ Ñ‡Ğ¸Ñ‚Ğ°ĞµÑ‚ Ñ„Ğ°Ğ¹Ğ» ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‡Ñ‚Ğ¾ ÑĞ¾Ğ·Ğ´Ğ°Ğ»
3. **Long Summary Generation** - 10+ ÑĞµĞºÑƒĞ½Ğ´ Ğ½Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾Ğ³Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ñ€ĞµĞ·ÑĞ¼Ğµ Ğ´Ğ»Ñ Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
4. **Verbose Prompts** - Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ñ‹ Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‚ structured JSON output Ñ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ°Ğ¼Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ

**ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾ Ñ„Ğ»Ğ¾Ñƒ:**
```
00:00 - Orchestrator: "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¼ ĞºÑ€Ğ°ÑĞ½ÑƒÑ ÑÑ„ĞµÑ€Ñƒ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ code-generator"
00:08 - Orchestrator â†’ Task (Ğ·Ğ°Ğ¿ÑƒÑĞº code-generator)
00:15 - code-generator â†’ Write (Ğ¿ĞµÑ€Ğ²Ğ°Ñ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚ĞºĞ°)
00:18 - code-generator â†’ Read (Ñ‡Ğ¸Ñ‚Ğ°ĞµÑ‚ Ñ‡Ñ‚Ğ¾ ÑĞ¾Ğ·Ğ´Ğ°Ğ»!) âŒ
00:23 - code-generator â†’ Write (Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµÑ‚!) âŒ
00:24 - File updated
00:34 - 10 Ğ¡Ğ•Ğš thinking Ğ´Ğ»Ñ Ñ€ĞµĞ·ÑĞ¼Ğµ âŒâŒâŒ
00:40 - Orchestrator Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ğ» Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
```

**Ğ§Ñ‚Ğ¾ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ:**

1. `backend/src/agents/code-generator.ts` (ÑÑ‚Ñ€Ğ¾ĞºĞ¸ 118-129, 209-217):
   - Ğ£Ğ±Ñ€Ğ°Ñ‚ÑŒ Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Ñ„Ğ°Ğ¹Ğ» Ğ¿Ğ¾ÑĞ»Ğµ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ
   - Ğ£Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¸Ñ‚ÑŒ Output Phase: ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¾Ğµ Ñ€ĞµĞ·ÑĞ¼Ğµ Ğ²Ğ¼ĞµÑÑ‚Ğ¾ JSON ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹
   - Ğ£Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸ "next steps"

2. `backend/src/orchestrator/conversation-orchestrator.ts`:
   - Ğ˜Ğ·Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğº ÑÑƒĞ±Ğ°Ğ³ĞµĞ½Ñ‚Ñƒ: "Confirm file created" Ğ²Ğ¼ĞµÑÑ‚Ğ¾ "Return a summary"

### ğŸ¯ Ğ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ ÑˆĞ°Ğ³Ğ¸:

**Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 1: Ğ£Ğ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ Direct Orchestrator (Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ)**
- [ ] ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ (ÑĞµĞ¹Ñ‡Ğ°Ñ 3-5 tool calls, Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ 1-2)
- [ ] Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ MCP server usage (Ğ°Ğ³ĞµĞ½Ñ‚ Ğ¿Ğ¾Ñ‡Ñ‚Ğ¸ Ğ½Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ)
- [ ] Ğ£Ğ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ error handling
- [ ] Ğ¡Ñ€Ğ°Ğ²Ğ½Ğ¸Ñ‚ÑŒ Ñ multi-agent Ğ½Ğ° master Ğ´Ğ»Ñ Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞ¸

**Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 2: ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Multi-Agent**
- [ ] Ğ£Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ñ‹ ÑÑƒĞ±Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² (ÑƒĞ±Ñ€Ğ°Ñ‚ÑŒ JSON output requirements)
- [ ] Ğ£Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ»Ğ¸ÑˆĞ½Ğ¸Ğµ read Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸
- [ ] Ğ¡Ğ¾ĞºÑ€Ğ°Ñ‚Ğ¸Ñ‚ÑŒ thinking time Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸ÑĞ¼Ğ¸

**Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 3: Ğ“Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´**
- [ ] Direct orchestrator Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ (ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ)
- [ ] Multi-agent Ğ´Ğ»Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… (Ñ€ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³, Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ)

### ğŸ“Š ĞšĞ°Ğº Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ÑŒ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ:

```bash
# 1. ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğ½Ğ° master Ğ´Ğ»Ñ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ
git checkout master
npm run backend

# 2. Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ñ‚Ğµ Ğ¶Ğµ Ñ‚ĞµÑÑ‚Ñ‹
time curl -X POST http://localhost:3001/api/conversation \
  -H "Content-Type: application/json" \
  -d '{"message":"ÑĞ¾Ğ·Ğ´Ğ°Ğ¹ ÑĞ¸Ğ½Ğ¸Ğ¹ ĞºÑƒĞ±","sessionId":"test_master_'$(date +%s)'"}'

# 3. Ğ¡Ñ€Ğ°Ğ²Ğ½Ğ¸Ñ‚ÑŒ trace Ñ„Ğ°Ğ¹Ğ»Ñ‹
cat logs/conversation-traces/conversation-*.json | jq '.metadata'

# 4. Ğ’ĞµÑ€Ğ½ÑƒÑ‚ÑŒÑÑ Ğ½Ğ° ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½ÑƒÑ Ğ²ĞµÑ‚ĞºÑƒ
git checkout experiment/direct-orchestrator-no-subagents
```

---

## Project Overview

**VRCreator2** is an AI-powered Mixed Reality development platform combining IWSDK (Immersive Web SDK) with Claude Agent SDK for natural language-driven AR/VR object creation and manipulation. Files created in `src/generated/` appear as virtual 3D objects in the real world through device camera, with instant hot reload.

## Development Commands

```bash
# Install dependencies
npm install

# Start backend (Agent SDK orchestrator + TypeScript compiler + WebSocket server)
npm run backend          # Single run
npm run backend:watch    # Auto-restart on changes

# Start frontend (Vite dev server with IWSDK plugins)
npm run dev

# Build for production
npm run build

# Preview production build
npm run preview
```

## Environment Setup

Copy `.env.example` to `.env` and configure:
- `ANTHROPIC_API_KEY` - Required for Claude API access
- `VITE_GEMINI_API_KEY` - Required for voice input (speech-to-text)
- `MESHY_API_KEY` - Optional, for AI-powered 3D model generation
- Agent-specific model overrides (see `.env.example` for all options)

**Note:** Backend uses Claude Code OAuth by default. API key is only needed for legacy `/api/orchestrate` endpoint.

**Get API Keys:**
- Gemini API: https://aistudio.google.com/app/apikey (free tier: 15 requests/min)
- Claude API: https://console.anthropic.com/
- Meshy AI: https://www.meshy.ai/

## Architecture Overview

### Three-Layer System

1. **Frontend (IWSDK + WebSocket Client)**
   - `src/index.ts` - Entry point, initializes IWSDK World
   - `src/live-code/client.ts` - WebSocket client that receives compiled code
   - `src/generated/` - Live code files (git-ignored, auto-cleaned on hot reload)
   - Each file = independent module with isolated entity tracking

2. **Backend Agent System (Claude Agent SDK)**
   - `backend/src/orchestrator/conversation-orchestrator.ts` - Main coordinator
   - `backend/src/agents/` - Specialized sub-agents (code-generator, code-editor, validator, scene-manager)
   - `backend/src/services/session-store.ts` - SQLite-based conversation persistence
   - `backend/src/config/agents.ts` - Centralized agent configuration

3. **Hot Reload Pipeline**
   - `backend/src/websocket/file-watcher.ts` - Monitors `src/generated/` with chokidar
   - `backend/src/tools/typescript-checker.ts` - Compiles TS â†’ wrapped JS with hot reload tracking
   - `backend/src/websocket/live-code-server.ts` - WebSocket server (port 3002)

### Multi-Agent Architecture

The system uses **5 specialized agents** coordinated by a main orchestrator:

**Orchestrator** (`conversation-orchestrator.ts`)
- Maintains conversation with user
- Delegates tasks to sub-agents
- Has minimal tools (only `read_file` for rare direct file inspection)
- Relies on sub-agent context isolation to keep conversation context clean

**Sub-agents:**

1. **code-generator** - Creates new IWSDK code from scratch
   - Model: `sonnet` (configurable via `AGENT_CODE_GENERATOR_MODEL`)
   - Tools: `Read`, `Write`
   - Use when: Creating new components, objects, scenes

2. **code-editor** - Modifies existing code
   - Model: `sonnet` with lower temperature (0.5)
   - Tools: `Read`, `Edit`, `Write`
   - Use when: Bug fixes, refactoring, adding features to existing files

3. **validator** - Code quality review
   - Model: `haiku` (faster, cheaper)
   - Tools: `Read`, `Glob`, `Grep` (read-only)
   - Use when: Quality checks after major changes

4. **scene-manager** - Scene operations
   - Model: `haiku`
   - Tools: `Bash`, `Read`, `Write`, `Glob`
   - Use when: Clearing scene (`rm -rf src/generated/*`), deleting specific objects, save/load scenes

5. **3d-model-generator** - AI-powered 3D model generation via Meshy AI
   - Model: `sonnet` with higher temperature (0.8)
   - Tools: `generate_3d_model` (custom), `Read`, `Write`
   - Use when: Creating 3D models, characters, game assets

**Key Design Principle:** Sub-agents read files in their **isolated context**. Their file reads don't pollute the orchestrator's context, enabling long conversations without context overflow.

### API Endpoints

**Primary:**
- `POST /api/conversation` - Multi-agent conversation with session management (uses Claude Code OAuth)

**Legacy:**
- `POST /api/orchestrate` - Single-turn orchestrator (requires `ANTHROPIC_API_KEY`)

**Utilities:**
- `POST /api/execute` - Direct code execution without AI
- `GET /health` - Health check

### Hot Reload Mechanism

**How it works:**

1. File created/changed in `src/generated/` â†’ chokidar detects
2. TypeScript compiled with wrapper:
   ```typescript
   const moduleId = 'module-timestamp';
   window.__LIVE_MODULES__ = window.__LIVE_MODULES__ || {};
   window.__LIVE_MODULES__[moduleId] = { entities: [], cleanup: () => {...} };
   window.__trackEntity = (entity, mesh) => { /* tracks for cleanup */ };
   // ... user code ...
   ```
3. WebSocket sends compiled code to client
4. Client executes code (entities created in scene)
5. On file change/delete: cleanup old module â†’ execute new code

**Result:** Edit TypeScript file â†’ see changes in AR/VR instantly

### MCP Server (IWSDK Documentation)

The project includes an MCP server (`mcp-server/`) that provides IWSDK documentation to agents:

**Location:** `mcp-server/dist/index.js` (auto-configured in conversation orchestrator)

**Resources exposed:**
- `iwsdk://api/types-map` - Complete type definitions
- `iwsdk://api/ecs/overview` - Entity-Component-System architecture
- `iwsdk://api/grabbing/overview` - VR grabbing system
- `iwsdk://api/physics` - Physics components
- `iwsdk://api/spatial-ui/overview` - UI system

**Usage by agents:** Agents can use `mcp_read_resource` tool to fetch documentation before generating code.

### Conversation Tracing

All conversation traces are saved to `logs/conversation-traces/` as JSON files:

**Format:** `conversation-{timestamp}-{sessionId}.json`

**Contents:**
- `metadata`: requestId, sessionId, duration, agentsUsed, toolsUsed, filesCreated, filesModified
- `trace`: Array of all messages exchanged with Agent SDK (timestamped)

**Use for:** Debugging agent behavior, analyzing tool calls, understanding MCP interactions

### Session Management

Conversations persist across backend restarts via SQLite:

**Database:** `backend/data/sessions.db`

**Schema:**
- `sessions` table: sessionId, messages (JSON), metadata (JSON), lastActivity

**Usage:** Include `sessionId` in `/api/conversation` requests to continue previous conversation.

## IWSDK Code Patterns

### Minimal Working Example

```typescript
import { World } from '@iwsdk/core';
import * as THREE from 'three';

const world = window.__IWSDK_WORLD__ as World;

// Create geometry and material
const geometry = new THREE.BoxGeometry(0.5, 0.5, 0.5);
const material = new THREE.MeshStandardMaterial({ color: 0xff0000 });
const mesh = new THREE.Mesh(geometry, material);

// Set position BEFORE creating entity
mesh.position.set(0, 1.5, -2);

// Create entity from mesh
const entity = world.createTransformEntity(mesh);

// REQUIRED: Track for hot reload
(window as any).__trackEntity(entity, mesh);
```

### Making Objects Interactive

```typescript
import { Interactable, DistanceGrabbable } from '@iwsdk/core';

// Make interactable
entity.addComponent(Interactable);

// Make grabbable in VR (up to 10m away)
entity.addComponent(DistanceGrabbable, {
  maxDistance: 10
});
```

### Common Geometries

- `BoxGeometry(width, height, depth)` - Cubes/boxes
- `SphereGeometry(radius, widthSegments, heightSegments)` - Spheres
- `CylinderGeometry(radiusTop, radiusBottom, height, segments)` - Cylinders
- `PlaneGeometry(width, height)` - Flat planes
- `TorusGeometry(radius, tube, radialSegments, tubularSegments)` - Toruses

### Materials

**MeshStandardMaterial (PBR - use by default):**
```typescript
new THREE.MeshStandardMaterial({
  color: 0xff0000,     // Hex color
  roughness: 0.7,      // 0 = smooth, 1 = rough
  metalness: 0.3       // 0 = non-metal, 1 = metal
})
```

**MeshBasicMaterial (unlit):**
```typescript
new THREE.MeshBasicMaterial({ color: 0x00ff00 })
```

## Agent Configuration System

All agent behavior is configurable via environment variables (see `.env.example`).

### Model Selection Strategy

**Default assignments:**
- **code-generator, code-editor, 3d-model-generator**: `sonnet` (balance of quality/speed)
- **validator, scene-manager**: `haiku` (faster, cheaper for simple tasks)

**Override per agent:**
```bash
AGENT_CODE_GENERATOR_MODEL=opus    # Use most powerful model
AGENT_VALIDATOR_MODEL=haiku        # Use fastest/cheapest
```

### Extended Thinking (Beta)

Enable "thinking before responding" for complex tasks:

```bash
AGENT_CODE_GENERATOR_THINKING_ENABLED=true
AGENT_CODE_GENERATOR_THINKING_BUDGET=4000  # Must be â‰¥1024, <MAX_TOKENS
```

**When to enable:** Complex refactoring, architectural decisions, debugging subtle bugs

### Temperature Guidelines

- **0.3-0.5**: Precise, deterministic (editing, validation)
- **0.7**: Balanced creativity (code generation)
- **0.8-1.0**: Creative (3D prompts, novel solutions)

## File Structure

```
vrcreator2/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ generated/          # Live code files (git-ignored, hot reload)
â”‚   â”œâ”€â”€ live-code/          # WebSocket client & code executor
â”‚   â””â”€â”€ index.ts            # IWSDK initialization
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ agents/         # 5 specialized AI agents
â”‚   â”‚   â”œâ”€â”€ orchestrator/   # Main conversation coordinator
â”‚   â”‚   â”œâ”€â”€ services/       # Session store (SQLite)
â”‚   â”‚   â”œâ”€â”€ websocket/      # File watcher + live code server
â”‚   â”‚   â”œâ”€â”€ tools/          # TypeScript compiler, custom tools
â”‚   â”‚   â”œâ”€â”€ config/         # Agent configuration system
â”‚   â”‚   â””â”€â”€ server.ts       # Express + WebSocket entry point
â”‚   â””â”€â”€ data/               # SQLite database
â”œâ”€â”€ mcp-server/             # IWSDK documentation MCP server
â”‚   â””â”€â”€ dist/index.js       # Built MCP server
â”œâ”€â”€ ui/                     # UIKitML UI definitions
â”‚   â””â”€â”€ welcome.uikitml     # Compiled to public/ui/welcome.json
â””â”€â”€ logs/
    â””â”€â”€ conversation-traces/  # JSON trace files (debugging)
```

## Important Notes

### Security Constraints

Agents can **ONLY** write to:
- `src/generated/` - Live code objects
- `backend/generated/` - Backend generated code

**Cannot modify:**
- Core project files (`src/index.ts`, `vite.config.js`, etc.)
- `node_modules/`
- Configuration files
- Build artifacts

### Hot Reload Requirements

**Every file MUST include:**
```typescript
(window as any).__trackEntity(entity, mesh);
```

**Why:** Without this, entities won't be cleaned up on file changes, causing duplicate objects in scene.

### WebSocket Connection

Frontend connects to `ws://localhost:3002` (or `VITE_WS_URL` env var).

**Common issue:** If hot reload doesn't work, check:
1. Backend WebSocket server running on port 3002
2. Browser console for WebSocket connection errors
3. `backend/data/sessions.db` permissions

### TypeScript Compilation

TypeScript is compiled **on the backend** before sending to client:
- Type errors are logged but don't block execution (failover to original code)
- Source maps not included (compiled code is ephemeral)
- Imports are resolved relative to project root

## Debugging

### Conversation Traces

Check `logs/conversation-traces/` for full Agent SDK message history:

```bash
# View latest trace
cat logs/conversation-traces/conversation-*.json | jq '.metadata'

# See which agents were used
cat logs/conversation-traces/conversation-*.json | jq '.metadata.agentsUsed'

# Count messages exchanged
cat logs/conversation-traces/conversation-*.json | jq '.trace | length'
```

### Backend Logs

Backend uses `pino` structured logging:

```bash
# Watch logs with pretty printing
npm run backend:watch

# Filter for specific module
npm run backend 2>&1 | grep "conversation-orchestrator"

# Filter for MCP tool calls
npm run backend 2>&1 | grep "ğŸ” MCP"
```

### Session Inspection

```bash
# View active sessions
sqlite3 backend/data/sessions.db "SELECT sessionId, lastActivity FROM sessions;"

# Clear all sessions
rm backend/data/sessions.db
```

## Testing the System

### Quick Test

```bash
# Start backend
npm run backend

# In another terminal, test conversation API
curl -X POST http://localhost:3001/api/conversation \
  -H "Content-Type: application/json" \
  -d '{"message":"Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹ Ñ„Ğ¸Ğ¾Ğ»ĞµÑ‚Ğ¾Ğ²Ñ‹Ğ¹ ĞºÑƒĞ± 0.5 Ğ¼ĞµÑ‚Ñ€Ğ°","sessionId":"test-1"}'
```

**Expected:** JSON response with `success: true`, file created at `src/generated/*.ts`

### Verify Hot Reload

1. Start backend + frontend
2. Open frontend in browser (https://localhost:8081/)
3. Create file in `src/generated/test-cube.ts` (use IWSDK pattern above)
4. Check browser console: "âœ… Module loaded: module-..."
5. Edit file â†’ changes appear instantly in AR/VR view

### MCP Server Test

Agents should automatically access documentation via MCP:

```bash
# Check MCP server can start
node mcp-server/dist/index.js

# Monitor logs for MCP resource reads
npm run backend 2>&1 | grep "mcp_read_resource"
```

## Voice Input (Speech-to-Text)

VRCreator2 includes voice input powered by **Gemini Multimodal API** for hands-free interaction in VR.

### Features

- **Automatic Language Detection** - Supports 100+ languages (Russian, English, etc.) without manual configuration
- **Push-to-Talk Interface** - Hold button to record, release to transcribe
- **Quest Browser Compatible** - Works with `getUserMedia` WebM audio
- **Retry Mechanism** - Automatic fallback to alternative models on overload
- **Real-time Transcription** - Fast response time (typically 1-2 seconds)

### Architecture

**Frontend Components:**
- `src/services/gemini-audio-service.ts` - Voice recording and transcription service
- `src/config/gemini.ts` - API configuration and settings
- `src/panel.ts` - UI integration (MIC button handlers)

**Recording Flow:**
1. User presses MIC button â†’ `GeminiAudioService.start()`
2. Browser requests microphone permission
3. `MediaRecorder` captures audio in WebM format
4. User releases button â†’ `GeminiAudioService.stop()`
5. Audio converted to base64
6. Sent to Gemini API with transcription prompt
7. Transcribed text returned to UI

**API Details:**
- Endpoint: `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent`
- Format: Inline data with `audio/webm` mime type
- Prompt: "Transcribe this audio exactly. Return ONLY the transcribed text, no other commentary."
- Config: Low temperature (0.1) for accurate transcription

### Usage Example

```typescript
import { GeminiAudioService } from './services/gemini-audio-service';

const voiceService = new GeminiAudioService();

// Check if supported
if (!voiceService.isSupported()) {
  console.error('Microphone not supported');
  return;
}

// Push-to-Talk pattern
button.addEventListener('pointerdown', async () => {
  await voiceService.start(); // Start recording
  button.style.backgroundColor = 'red'; // Visual feedback
});

button.addEventListener('pointerup', async () => {
  button.style.backgroundColor = 'yellow'; // Processing

  const text = await voiceService.stop(); // Transcribe
  console.log('Transcribed:', text);

  button.style.backgroundColor = 'gray'; // Done
});
```

### Configuration

Required environment variable in `.env`:
```bash
VITE_GEMINI_API_KEY=your_api_key_here
GEMINI_MODEL=gemini-2.0-flash
```

Get your API key at: https://aistudio.google.com/app/apikey

**Rate Limits (Free Tier):**
- 15 requests per minute
- 1,500 requests per day
- 1 million tokens per day

### Error Handling

The service includes robust error handling:
- **Microphone denied** - Clear error message to user
- **API overload (503/429)** - Automatic retry with 2-second delay
- **Model unavailable** - Fallback to alternative model
- **Short recording** - Reject recordings under 100ms
- **Network errors** - Detailed error messages in console

### Browser Compatibility

| Browser | Recording | Transcription |
|---------|-----------|--------------|
| Chrome Desktop | âœ… | âœ… |
| Meta Quest Browser | âœ… | âœ… |
| Safari iOS | âš ï¸ (requires user gesture) | âœ… |
| Firefox | âœ… | âœ… |

**Note:** All browsers require **HTTPS** for `getUserMedia` (except localhost).

### Debugging

Enable verbose logging:
```typescript
// Console output shows:
// ğŸ¤ Recording started
// ğŸš€ Sending audio to gemini-2.0-flash (attempt 1/2)...
// âœ… Transcription: "ÑĞ¾Ğ·Ğ´Ğ°Ğ¹ ĞºÑ€Ğ°ÑĞ½Ñ‹Ğ¹ ĞºÑƒĞ±"
```

Check API key configuration:
```typescript
import { isGeminiConfigured } from './config/gemini';

if (!isGeminiConfigured()) {
  console.error('Gemini API key not set in .env');
}
```

### Cost Optimization

- Free tier covers most development and testing
- Each transcription request counts as ~1,000-2,000 tokens
- Approximate cost (paid tier): $0.001-0.002 per transcription
- Consider caching common phrases or commands

### Future Enhancements

- [ ] Add voice activity detection (stop on silence)
- [ ] Support custom wake words ("Hey VRCreator")
- [ ] Add local Whisper.cpp fallback for offline mode
- [ ] Implement streaming transcription for longer recordings
- [ ] Add voice commands for common actions
