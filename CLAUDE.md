# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## üí¨ Canvas Chat System - How It Works

**Current Status:** ‚úÖ **WORKING** - Voice input + backend conversation API fully integrated

### Architecture Overview

The chat system uses **Canvas** (not UIKit) for rendering messages in VR:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Canvas Chat System (1024x1024 texture)    ‚îÇ
‚îÇ                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ [User message - blue bubble]       ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                  [Assistant - gray]‚îÇ    ‚îÇ
‚îÇ  ‚îÇ [User message - blue bubble]       ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îÇ
‚îÇ  ‚îÇ Placeholder ‚îÇ  üé§  ‚îÇ ‚Üê 3D invisible     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    sphere (0.05m)  ‚îÇ
‚îÇ     "Listening..." ‚Üê Status text           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Key Files

**Frontend:**
- `src/canvas-chat-system.ts` - Main chat system (Canvas rendering, voice, backend API)
- `src/canvas-chat-interaction.ts` - 3D mic button interaction (IWSDK ECS)
- `src/services/gemini-audio-service.ts` - Voice recording + Gemini transcription
- `src/services/audio-feedback.ts` - Sound effects (beeps)
- `src/live-code/client.ts` - WebSocket client (receives tool progress from backend)

**Backend:**
- `backend/src/orchestrator/conversation-orchestrator.ts` - Main AI orchestrator
- `backend/src/websocket/live-code-server.ts` - Broadcasts tool progress events
- `backend/src/services/session-store.ts` - SQLite session persistence

### Voice Input Flow (Push-to-Talk)

1. **User presses mic button** (3D sphere)
   - `CanvasChatInteractionSystem` detects `Pressed` tag
   - Calls `canvasChatSystem.startRecording()`
   - üîä Beep sound (1kHz)
   - Canvas shows: "Listening..."
   - MediaRecorder starts capturing audio

2. **User speaks** (while holding button)
   - Audio recorded in WebM format

3. **User releases button**
   - `CanvasChatInteractionSystem` detects `Pressed` removed
   - Calls `canvasChatSystem.stopRecording()`
   - üîä Beep sound (600Hz)
   - Canvas shows: "Transcribing..."
   - Audio ‚Üí base64 ‚Üí POST to Gemini API
   - **1-2 seconds** ‚Üí transcribed text received

4. **Send to backend**
   - Canvas shows: "Sending..."
   - POST `/api/conversation` with `{ message, sessionId }`
   - Backend orchestrator processes request

5. **Backend processing** (WebSocket events)
   - `agent_thinking` ‚Üí Canvas shows: "First I'll read the file..."
   - `tool_use_start` ‚Üí Canvas shows: "Using Write..."
   - `tool_use_complete` ‚Üí Canvas shows: "‚úì Write complete" (2s)
   - File changes ‚Üí WebSocket `load_file` ‚Üí 3D object appears

6. **Response received**
   - Canvas shows assistant message
   - üîä Success beeps (ascending)
   - Status cleared

### 3D Mic Button (Invisible Sphere)

The mic button is a **semi-transparent 3D sphere** positioned over the Canvas mic icon:

```typescript
// Position calculation (canvas-chat-system.ts:143-150)
const offsetX = (944 / 1024 - 0.5) * 2;  // Canvas button X
const offsetY = -(924 / 1024 - 0.5) * 2; // Canvas button Y (inverted)

micButtonMesh.position.set(
  panelPosition.x + offsetX,  // Right side of panel
  panelPosition.y + offsetY,  // Bottom of panel
  panelPosition.z + 0.05      // Slightly in front
);
```

**Why 3D sphere instead of Canvas hit detection?**
- IWSDK Pressed/Hovered tags work automatically
- No need to convert raycast hit ‚Üí Canvas coordinates
- Same pattern as Robot system (reliable)

### Status Indicators

**Visual (Canvas text below mic button):**
- "Listening..." (blue) - Recording
- "Transcribing..." (blue, animated dots) - Speech-to-text
- "Sending..." (blue, animated dots) - POST to backend
- "Using Write..." (blue) - Agent using tool (from WebSocket)
- "‚úì Write complete" (gray, 2s timeout)
- Errors: "Recording failed", "Could not transcribe", etc.

**Audio (Web Audio API):**
- üîä High beep (1kHz, 80ms) - Recording start
- üîä Low beep (600Hz, 120ms) - Recording stop
- üîä 3 ascending beeps - Success
- üîä 3 descending beeps - Error

### WebSocket Events (Backend ‚Üí Frontend)

LiveCodeClient (`src/live-code/client.ts`) forwards to Canvas chat:

```typescript
case 'tool_use_start':
  canvasChat.showToolProgress(toolName, 'starting');
  // Shows: "Using Write..."

case 'tool_use_complete':
  canvasChat.showToolProgress(toolName, 'completed');
  // Shows: "‚úì Write complete" (2s)

case 'agent_thinking':
  canvasChat.showThinkingMessage(text);
  // Shows: "First I'll read the file..." (truncated to 50 chars)
```

### Session Management & Memory System

**Status:** ‚úÖ **FULLY WORKING** - Agent remembers conversation context within session, resets on page reload

#### How Memory Works

**Frontend (Session ID generation):**
```typescript
// canvas-chat-system.ts:730-738 & panel.ts:276-283
// NEW sessionId generated on EVERY page reload (stored in window, not localStorage)
if (!(window as any).__VR_SESSION_ID__) {
  (window as any).__VR_SESSION_ID__ = `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  console.log('üÜï New session started:', (window as any).__VR_SESSION_ID__);
}
```

**Backend (SQLite + System Prompt):**
1. **Session Store** (`backend/data/sessions.db`): Persists all conversation history
2. **History Injection**: Backend loads history and injects it into Agent SDK system prompt

```typescript
// conversation-orchestrator.ts:342-361
const historyMessages = conversationHistory.slice(0, -1);
conversationHistoryText = '\n\n## Previous Conversation\n\n' +
  historyMessages.map(msg => {
    const content = typeof msg.content === 'string' ? msg.content : JSON.stringify(msg.content);
    return `**${msg.role === 'user' ? 'User' : 'Assistant'}:** ${content}`;
  }).join('\n\n');

// conversation-orchestrator.ts:676
systemPrompt: DIRECT_SYSTEM_PROMPT + conversationHistoryText
```

**Why system prompt instead of messages parameter?**
- Agent SDK `query()` doesn't support `messages` parameter in options (it's ignored)
- History embedded in systemPrompt works reliably across all Agent SDK versions
- Allows agent to reference previous conversation naturally

#### Memory Behavior

**Within same session:**
```
User: "–ó–∞–ø–æ–º–Ω–∏ —á–∏—Å–ª–æ 25"
Assistant: "–ó–∞–ø–æ–º–Ω–∏–ª: **25**."

User: "–ö–∞–∫–æ–µ —á–∏—Å–ª–æ —Ç—ã –∑–∞–ø–æ–º–Ω–∏–ª?"
üìö Conversation history added to system prompt (2 messages, 83 chars)
Assistant: "–Ø –∑–∞–ø–æ–º–Ω–∏–ª —á–∏—Å–ª–æ **25**." ‚Üê ‚úÖ REMEMBERS!
```

**After page reload:**
```
[Page refresh ‚Üí new window.__VR_SESSION_ID__]

User: "–ö–∞–∫–æ–µ —á–∏—Å–ª–æ —Ç–µ–±–µ –Ω–∞–¥–æ –±—ã–ª–æ –∑–∞–ø–æ–º–Ω–∏—Ç—å?"
üìö New conversation (no history)
Assistant: "–Ø –Ω–µ –ø–æ–ª—É—á–∞–ª –Ω–∏–∫–∞–∫–æ–≥–æ —á–∏—Å–ª–∞... —ç—Ç–æ –ø–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ." ‚Üê ‚úÖ FRESH START!
```

#### Debugging Memory

**Check backend logs:**
```bash
# Session started with history
üìö Conversation history added to system prompt
  sessionId: "session_1765033153429_0hcv6wltu"
  totalMessages: 3
  historyMessagesIncluded: 2
  historyTextLength: 83

# New session (no history)
üìö New conversation (no history)
  sessionId: "session_1765033228126_h1a9g50ax"
```

**Check conversation traces:**
```bash
# View latest conversation with history
cat logs/conversation-traces/conversation-*.json | jq '.metadata.historyMessagesIncluded'

# View session in SQLite
sqlite3 backend/data/sessions.db "SELECT sessionId, json_array_length(messages) FROM sessions;"
```

#### Key Files

**Session Management:**
- `src/canvas-chat-system.ts:730-738` - Session ID generation (window scope)
- `src/panel.ts:276-283` - Session ID getter (shared logic)
- `backend/src/services/session-store.ts` - SQLite persistence
- `backend/src/orchestrator/conversation-orchestrator.ts:342-361` - History formatting
- `backend/src/orchestrator/conversation-orchestrator.ts:676` - System prompt injection

**Database:**
- `backend/data/sessions.db` - SQLite database
- TTL: 7 days (automatic cleanup)
- Schema: sessionId, messages (JSON), metadata, timestamps

### Debugging Tips

**Check Canvas Chat is initialized:**
```javascript
window.__CANVAS_CHAT__  // Should be CanvasChatSystem instance
```

**Check mic button entity:**
```javascript
// Should have Interactable + MicButton components
```

**Check WebSocket connection:**
```javascript
// Backend logs show:
// "üì° WebSocket client connected"
// "Message broadcast to clients"
```

**Check session:**
```bash
sqlite3 backend/data/sessions.db "SELECT sessionId, json_array_length(messages) FROM sessions;"
```

**Check voice service:**
```javascript
window.__CANVAS_CHAT__.voiceService.isSupported()  // Should be true
```

**Common issues:**
- No audio permission ‚Üí Check browser console for MediaRecorder errors
- No Gemini API key ‚Üí Check `.env` has `VITE_GEMINI_API_KEY`
- Status not showing ‚Üí Check LiveCodeClient is forwarding to `__CANVAS_CHAT__`
- Mic button not clickable ‚Üí Check entity has `Interactable` + `MicButton` components

---

## üìä Logging & Conversation History

**–ì–¥–µ —Ö—Ä–∞–Ω—è—Ç—Å—è —Å–æ–æ–±—â–µ–Ω–∏—è —á–∞—Ç–∞:**

### 1. Conversation Trace Files (JSON)

**–õ–æ–∫–∞—Ü–∏—è:** `logs/conversation-traces/conversation-{timestamp}-{sessionId}.json`

**–°–æ–¥–µ—Ä–∂–∏–º–æ–µ:**
- `metadata` - –ö—Ä–∞—Ç–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–∞–∑–≥–æ–≤–æ—Ä–µ
  - `requestId`, `sessionId` - –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã
  - `userMessage` - –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
  - `duration`, `durationSeconds` - –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
  - `agentsUsed`, `toolsUsed` - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã –∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
  - `filesCreated`, `filesModified` - –°–æ–∑–¥–∞–Ω–Ω—ã–µ/–∏–∑–º–µ–Ω—ë–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
  - `experimentMode` - –†–µ–∂–∏–º –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞ (direct/multi-agent)

- `readableFlow` - –ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π —Ñ–ª–æ—É –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
  ```
  "[0.0s] User: \"–¢–µ–ø–µ—Ä—å —Å–æ–∑–¥–∞–π –∫—Ä—É—Ç—è—â–∏–π—Å—è –∫—É–±.\""
  "[7.6s] Agent used: Write"
  "[7.6s] üîß Tool #1: Write ‚Üí src/generated/spinning-cube.ts"
  "[7.7s]    ‚úì Tool succeeded"
  "[10.8s] Assistant text: \"‚úì –°–æ–∑–¥–∞–ª –∫—Ä—É—Ç—è—â–∏–π—Å—è –∫—É–±!\""
  ```

- `trace` - –ü–æ–ª–Ω—ã–π –ª–æ–≥ –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π Agent SDK
  - –ö–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: `timestamp`, `elapsedSeconds`, `timeSinceLastMessage`, `message`
  - –¢–∏–ø—ã: `system`, `user`, `assistant`, `tool_result`

**–ö–∞–∫ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–∞–∑–≥–æ–≤–æ—Ä—ã:**
```bash
# –ü–æ–∫–∞–∑–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Ñ–∞–π–ª–æ–≤
ls -lt logs/conversation-traces/ | head -6

# –ù–∞–π—Ç–∏ —Ñ–∞–π–ª—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 –º–∏–Ω—É—Ç
find logs/conversation-traces -type f -name "*.json" -mmin -10

# –ü–æ–∫–∞–∑–∞—Ç—å metadata –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
cat logs/conversation-traces/conversation-*.json | jq '.metadata'

# –ü–æ–∫–∞–∑–∞—Ç—å readableFlow (–∫—Ä–∞—Ç–∫–∏–π —Ñ–ª–æ—É)
cat logs/conversation-traces/conversation-*.json | jq -r '.readableFlow[]'

# –ü–æ—Å—á–∏—Ç–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ trace
cat logs/conversation-traces/conversation-*.json | jq '.trace | length'

# –ù–∞–π—Ç–∏ –≤—Å–µ tool calls
cat logs/conversation-traces/conversation-*.json | jq '[.trace[].message.message.content[]? | select(.type? == "tool_use") | .name] | unique'
```

### 2. Backend Console Logs (Pino)

**–ì–¥–µ —Å–º–æ—Ç—Ä–µ—Ç—å:** Real-time –≤—ã–≤–æ–¥ `npm run backend`

**–ö–ª—é—á–µ–≤—ã–µ –ª–æ–≥–∏:**

**Conversation Request:**
```
[15:37:21.701] INFO: Conversation request started
    requestId: "3914f19d-5af2-4ed2-ac7c-feb866e5bd11"
    message: "–¢–µ–ø–µ—Ä—å —Å–æ–∑–¥–∞–π –∫—Ä—É—Ç—è—â–∏–π—Å—è –∫—É–±."
    sessionId: "session_1765035423941_kra2iap8j"
```

**Session History:**
```
[15:37:21.702] INFO: üìö Conversation history added to system prompt
    sessionId: "session_1765035423941_kra2iap8j"
    totalMessages: 3
    historyMessagesIncluded: 2
    historyTextLength: 92
```

**Tool Execution:**
```
[15:37:29.348] INFO: üîß Tool #1: Write
    toolName: "Write"
    toolInput: "{\"file_path\":\"src/generated/spinning-cube.ts\",...}"
    timeSinceLastMessage: 6483
    elapsedTotal: 7647
```

**Completion:**
```
[15:37:32.562] INFO: ‚ö° Completed in 10.9s | 1 tool calls | 0 files created
    duration: 10861
    toolsUsed: ["Write"]
    agentsUsed: ["Write"]
    messageLength: 59
```

**Speech-to-Text:**
```
[15:37:02.532] INFO: Sending audio to Gemini API
    model: "gemini-2.0-flash"
    audioLength: 40324
    audioSizeMB: "0.03"

[15:37:03.747] INFO: Speech transcribed successfully
    duration: 1215
    textLength: 22  # "–ü—Ä–∏–≤–µ—Ç, –æ—á–∏—Å—Ç–∏ —Å—Ü–µ–Ω—É." = 22 —Å–∏–º–≤–æ–ª–∞
```

**WebSocket Events:**
```
[15:37:08.967] INFO: Message broadcast to clients
    action: "tool_use_start"
    clientCount: 2
    payloadSize: 213

[15:37:09.078] INFO: Message broadcast to clients
    action: "tool_use_complete"
    clientCount: 2
```

**Filtering Logs:**
```bash
# –¢–æ–ª—å–∫–æ conversation logs
npm run backend 2>&1 | grep "conversation-orchestrator"

# –¢–æ–ª—å–∫–æ WebSocket events
npm run backend 2>&1 | grep "websocket:live-code"

# –¢–æ–ª—å–∫–æ speech-to-text
npm run backend 2>&1 | grep "speech-to-text"

# –¢–æ–ª—å–∫–æ tool calls
npm run backend 2>&1 | grep "üîß Tool"
```

### 3. SQLite Session Database

**–§–∞–π–ª:** `backend/data/sessions.db`

**Schema:**
```sql
CREATE TABLE sessions (
  session_id TEXT PRIMARY KEY,
  messages TEXT NOT NULL,        -- JSON array of conversation history
  agents_used TEXT,              -- JSON array
  tools_used TEXT,               -- JSON array
  files_created TEXT,            -- JSON array
  files_modified TEXT,           -- JSON array
  total_input_tokens INTEGER,
  total_output_tokens INTEGER,
  created_at INTEGER NOT NULL,
  updated_at INTEGER NOT NULL,
  expires_at INTEGER NOT NULL    -- TTL: 7 days
);
```

**–ö–∞–∫ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Å–µ—Å—Å–∏–∏:**
```bash
# –°–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–µ—Å—Å–∏–π
sqlite3 backend/data/sessions.db "SELECT session_id, datetime(created_at/1000, 'unixepoch', 'localtime') as created FROM sessions;"

# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –∫–∞–∂–¥–æ–π —Å–µ—Å—Å–∏–∏
sqlite3 backend/data/sessions.db "SELECT session_id, json_array_length(messages) as msg_count FROM sessions;"

# –ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å–µ—Å—Å–∏–∏
sqlite3 backend/data/sessions.db "SELECT json_pretty(messages) FROM sessions WHERE session_id = 'session_1765035423941_kra2iap8j';"

# –ü–æ–∫–∞–∑–∞—Ç—å metadata
sqlite3 backend/data/sessions.db "SELECT session_id, agents_used, tools_used FROM sessions;"

# –û—á–∏—Å—Ç–∏—Ç—å –≤—Å–µ —Å–µ—Å—Å–∏–∏
rm backend/data/sessions.db
```

### 4. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–µ–∂–¥—É –ª–æ–≥–∞–º–∏

**–ü—Ä–∏–º–µ—Ä:** –ó–∞–ø—Ä–æ—Å "–¢–µ–ø–µ—Ä—å —Å–æ–∑–¥–∞–π –∫—Ä—É—Ç—è—â–∏–π—Å—è –∫—É–±."

| –ò—Å—Ç–æ—á–Ω–∏–∫ | –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä | –í—Ä–µ–º—è | –î–∞–Ω–Ω—ã–µ |
|----------|--------------|-------|--------|
| Backend console | requestId: `3914f19d-...` | 15:37:21 | Real-time –ª–æ–≥–∏ |
| Trace file | `conversation-2025-12-06T15-37-32-562Z-session_.json` | 15:37:32 | –ü–æ–ª–Ω—ã–π trace |
| SQLite DB | sessionId: `session_1765035423941_kra2iap8j` | - | –í—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å–µ—Å—Å–∏–∏ |
| Speech-to-text | - | 15:37:20 | –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ (30 —Å–∏–º–≤–æ–ª–æ–≤) |

**–í—Å–µ –ª–æ–≥–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–ø–∞–¥–∞—é—Ç:**
- ‚úÖ User message
- ‚úÖ Tool calls (Write ‚Üí spinning-cube.ts)
- ‚úÖ Duration (10.86s)
- ‚úÖ SessionId
- ‚úÖ Speech-to-text transcription

---

## ‚ùå DEPRECATED: UIKit Input (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)

**–ü—Ä–æ–±–ª–µ–º–∞:** –ù–µ –º–æ–∂–µ–º –Ω–æ—Ä–º–∞–ª—å–Ω–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ UIKit Input –≤ VR

**–ü—Ä–æ–±–ª–µ–º–∞:** –ù–µ –º–æ–∂–µ–º –Ω–æ—Ä–º–∞–ª—å–Ω–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ UIKit Input –≤ VR

**–ß—Ç–æ –ø—Ä–æ–±–æ–≤–∞–ª–∏:**
- ‚ùå `messageInput.value` - undefined
- ‚ùå `messageInput.properties.value` - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç Proxy –æ–±—ä–µ–∫—Ç, –Ω–µ —Å—Ç—Ä–æ–∫—É
- ‚ùå `messageInput.properties.value.value` - –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç `.trim()`
- ‚ùå Polling –∫–∞–∂–¥—ã–π frame - –Ω–µ –≤–∏–¥–∏—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è
- ‚ùå propertyChangedSignal.subscribe() - –Ω–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç
- ‚ùå Event listeners (focus, blur, input) - –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç –≤ VR

**–ß—Ç–æ –¥–æ–ª–∂–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å (–ø–æ —Ç–∏–ø–∞–º):**
- ‚úÖ `Input.currentSignal.value` - ReadonlySignal<string>
- ‚úÖ `Input.element.value` - HTMLInputElement –Ω–∞–ø—Ä—è–º—É—é
- ‚úÖ `Input.element.addEventListener('keydown')` - —Å–ª—É—à–∞—Ç—å Enter

**–¢–∏–ø—ã –∏–∑ `@pmndrs/uikit/dist/components/input.d.ts`:**
```typescript
export declare class Input {
    readonly element: HTMLInputElement | HTMLTextAreaElement;
    readonly currentSignal: ReadonlySignal<string>;
    readonly hasFocus: Signal<boolean>;
}
```

**–ù—É–∂–Ω–æ:**
1. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å `currentSignal.value` –≤ VR
2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–±–æ—Ç–∞–µ—Ç –ª–∏ `element.addEventListener('keydown')`
3. –ï—Å–ª–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç - –≤–æ–∑–º–æ–∂–Ω–æ –±–∞–≥ –≤ IWSDK –∏–ª–∏ –Ω—É–∂–µ–Ω –¥—Ä—É–≥–æ–π –ø–æ–¥—Ö–æ–¥

**–§–∞–π–ª—ã:**
- `src/panel.ts:94-144` - —Ç–µ–∫—É—â–∞—è –ø–æ–ø—ã—Ç–∫–∞ —Ä–∞–±–æ—Ç—ã —Å Input
- `node_modules/@pmndrs/uikit/dist/components/input.d.ts` - —Ç–∏–ø—ã

---

## üß™ UI Dynamic Chat Test Results (2025-12-05)

**–¶–µ–ª—å:** –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è/—É–¥–∞–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –≤ UIKit –ø–∞–Ω–µ–ª—å

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** ‚úÖ **–†–ê–ë–û–¢–ê–ï–¢!**

### –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:

| –§—É–Ω–∫—Ü–∏—è | –°—Ç–∞—Ç—É—Å | API |
|---------|--------|-----|
| –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ | ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç | `container.add(new UIKit.Text({...}))` |
| –£–¥–∞–ª–µ–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ | ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç | `container.remove(element)` |
| –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ CSS –∫–ª–∞—Å—Å–æ–≤ | ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç | `element.classList.add('class-name')` |
| –î–æ—Å—Ç—É–ø –∫ document | ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç | `window.__PANEL_DOCUMENT__` |

### –í—ã–≤–æ–¥—ã:

1. **UIKit –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π UI** - –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–ª—è—Ç—å/—É–¥–∞–ª—è—Ç—å —ç–ª–µ–º–µ–Ω—Ç—ã –≤ runtime
2. **–ì–æ—Ç–æ–≤ –∫ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —á–∞—Ç–∞** - backend –º–æ–∂–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è —á–µ—Ä–µ–∑ WebSocket, frontend –¥–æ–±–∞–≤–ª—è–µ—Ç –∏—Ö –≤ –ø–∞–Ω–µ–ª—å
3. **–°—Ç–∏–ª–∏ —Ä–∞–±–æ—Ç–∞—é—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏** - `classList.add()` –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∫ –Ω–æ–≤—ã–º —ç–ª–µ–º–µ–Ω—Ç–∞–º

### –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏ –¥–ª—è —á–∞—Ç–∞:

- [ ] –î–æ–±–∞–≤–∏—Ç—å WebSocket action `update_chat` –≤ `types.ts`
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤ `client.ts`
- [ ] –°–æ–∑–¥–∞—Ç—å ChatSystem –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
- [ ] –î–æ–±–∞–≤–∏—Ç—å –∞–≤—Ç–æ—Å–∫—Ä–æ–ª–ª–∏–Ω–≥ –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É —Å–æ–æ–±—â–µ–Ω–∏—é
- [ ] –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Å backend conversation API

---

## üî¨ Performance Testing Results (2025-12-05)

**–ü—Ä–æ–±–ª–µ–º–∞:** Multi-agent –ø–æ–¥—Ö–æ–¥ —Å —Å—É–±–∞–≥–µ–Ω—Ç–∞–º–∏ —Å–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω—ã–π (40+ —Å–µ–∫—É–Ω–¥ –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á)

**–†–µ—à–µ–Ω–∏–µ:** –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π direct orchestrator –±–µ–∑ —Å—É–±–∞–≥–µ–Ω—Ç–æ–≤

**–í–µ—Ç–∫–∞:** `experiment/direct-orchestrator-no-subagents`

### ‚úÖ –î–æ—Å—Ç–∏–≥–Ω—É—Ç—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:

| –ó–∞–¥–∞—á–∞ | Multi-agent | Direct | –£–ª—É—á—à–µ–Ω–∏–µ | Tool calls |
|--------|-------------|--------|-----------|------------|
| –ü—Ä–æ—Å—Ç–æ–π –æ–±—ä–µ–∫—Ç (–∫—É–±/—Å—Ñ–µ—Ä–∞) | ~40s | **11-14s** | **3x –±—ã—Å—Ç—Ä–µ–µ** | 1 |
| –°–æ–ª–Ω–µ—á–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ (126 —Å—Ç—Ä–æ–∫) | N/A | **30.8s** | - | 1 |
| –¢–µ—Ç—Ä–∏—Å VR (593 —Å—Ç—Ä–æ–∫–∏) | N/A | **76.8s** | - | 1 |
| –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞ | N/A | **19-50s** | - | 3-5 |
| –û—á–∏—Å—Ç–∫–∞ —Å—Ü–µ–Ω—ã | N/A | **8s** | - | 1 |

**–ö–ª—é—á–µ–≤—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:**
- ‚úÖ **3x —É—Å–∫–æ—Ä–µ–Ω–∏–µ** –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á
- ‚úÖ **1 tool call** –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è (–≤–º–µ—Å—Ç–æ 5+ –≤ multi-agent)
- ‚úÖ **–ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—É—Ç–∏** (src/generated/) —á–µ—Ä–µ–∑ options.cwd
- ‚úÖ **–ü–æ–ª–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã** DistanceGrabbable —Å MovementMode
- ‚úÖ **Hot reload fix** - —Å—Ç–∞—Ä—ã–µ –æ–±—ä–µ–∫—Ç—ã —É–¥–∞–ª—è—é—Ç—Å—è –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏

### –ß—Ç–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–ª–∏:

**–ö–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç:**

```bash
# Terminal 1: –ó–∞–ø—É—Å—Ç–∏—Ç—å backend —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
npm run backend

# Terminal 2: –û—Ç–ø—Ä–∞–≤–∏—Ç—å –ø—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å –∏ –∑–∞–º–µ—Ä–∏—Ç—å –≤—Ä–µ–º—è
time curl -X POST http://localhost:3001/api/conversation \
  -H "Content-Type: application/json" \
  -d '{
    "message": "—Å–æ–∑–¥–∞–π –∫—Ä–∞—Å–Ω—É—é —Å—Ñ–µ—Ä—É",
    "sessionId": "test_perf_$(date +%s)"
  }'
```

**–ö–∞–∫ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:**

```bash
# 1. –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π trace —Ñ–∞–π–ª
ls -lt logs/conversation-traces/ | head -2

# 2. –ü–æ–∫–∞–∑–∞—Ç—å metadata (–≤—Ä–µ–º—è, –∞–≥–µ–Ω—Ç—ã, tools)
cat logs/conversation-traces/conversation-*.json | jq '.metadata'

# 3. –ü–æ–∫–∞–∑–∞—Ç—å —Ñ–ª–æ—É –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π —Å —Ç–∞–π–º–∏–Ω–≥–∞–º–∏
cat logs/conversation-traces/conversation-*.json | jq -r '.trace[] | "\(.timestamp) | \(.message.type // "unknown")"'

# 4. –ü–æ—Å—á–∏—Ç–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π
cat logs/conversation-traces/conversation-*.json | jq '.trace | length'

# 5. –ù–∞–π—Ç–∏ –≤—Å–µ tool calls
cat logs/conversation-traces/conversation-*.json | jq '[.trace[].message.message.content[]? | select(.type? == "tool_use") | .name] | unique'
```

**–ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã:**

1. **Double Write** - code-generator –ø–∏—à–µ—Ç —Ñ–∞–π–ª –¥–≤–∞–∂–¥—ã (—Å–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞—ë—Ç, –ø–æ—Ç–æ–º –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç)
2. **Unnecessary Read** - –∞–≥–µ–Ω—Ç —á–∏—Ç–∞–µ—Ç —Ñ–∞–π–ª –∫–æ—Ç–æ—Ä—ã–π —Ç–æ–ª—å–∫–æ —á—Ç–æ —Å–æ–∑–¥–∞–ª
3. **Long Summary Generation** - 10+ —Å–µ–∫—É–Ω–¥ –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∑—é–º–µ –¥–ª—è –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞
4. **Verbose Prompts** - –ø—Ä–æ–º–ø—Ç—ã —Ç—Ä–µ–±—É—é—Ç structured JSON output —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

**–ü—Ä–∏–º–µ—Ä –ø—Ä–æ–±–ª–µ–º–Ω–æ–≥–æ —Ñ–ª–æ—É:**
```
00:00 - Orchestrator: "–°–æ–∑–¥–∞–º –∫—Ä–∞—Å–Ω—É—é —Å—Ñ–µ—Ä—É —Å –ø–æ–º–æ—â—å—é code-generator"
00:08 - Orchestrator ‚Üí Task (–∑–∞–ø—É—Å–∫ code-generator)
00:15 - code-generator ‚Üí Write (–ø–µ—Ä–≤–∞—è –ø–æ–ø—ã—Ç–∫–∞)
00:18 - code-generator ‚Üí Read (—á–∏—Ç–∞–µ—Ç —á—Ç–æ —Å–æ–∑–¥–∞–ª!) ‚ùå
00:23 - code-generator ‚Üí Write (–ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç!) ‚ùå
00:24 - File updated
00:34 - 10 –°–ï–ö thinking –¥–ª—è —Ä–µ–∑—é–º–µ ‚ùå‚ùå‚ùå
00:40 - Orchestrator –ø–æ–ª—É—á–∏–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç
```

**–ß—Ç–æ –Ω—É–∂–Ω–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å:**

1. `backend/src/agents/code-generator.ts` (—Å—Ç—Ä–æ–∫–∏ 118-129, 209-217):
   - –£–±—Ä–∞—Ç—å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ —á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è
   - –£–ø—Ä–æ—Å—Ç–∏—Ç—å Output Phase: –∫–æ—Ä–æ—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –≤–º–µ—Å—Ç–æ JSON —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
   - –£–±—Ä–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏ "next steps"

2. `backend/src/orchestrator/conversation-orchestrator.ts`:
   - –ò–∑–º–µ–Ω–∏—Ç—å –ø—Ä–æ–º–ø—Ç –∫ —Å—É–±–∞–≥–µ–Ω—Ç—É: "Confirm file created" –≤–º–µ—Å—Ç–æ "Return a summary"

### üéØ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:

**–í–∞—Ä–∏–∞–Ω—Ç 1: –£–ª—É—á—à–∏—Ç—å Direct Orchestrator (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)**
- [ ] –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (—Å–µ–π—á–∞—Å 3-5 tool calls, –º–æ–∂–µ—Ç –±—ã—Ç—å 1-2)
- [ ] –î–æ–±–∞–≤–∏—Ç—å MCP server usage (–∞–≥–µ–Ω—Ç –ø–æ—á—Ç–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é)
- [ ] –£–ª—É—á—à–∏—Ç—å error handling
- [ ] –°—Ä–∞–≤–Ω–∏—Ç—å —Å multi-agent –Ω–∞ master –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏

**–í–∞—Ä–∏–∞–Ω—Ç 2: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å Multi-Agent**
- [ ] –£–ø—Ä–æ—Å—Ç–∏—Ç—å –ø—Ä–æ–º–ø—Ç—ã —Å—É–±–∞–≥–µ–Ω—Ç–æ–≤ (—É–±—Ä–∞—Ç—å JSON output requirements)
- [ ] –£–±—Ä–∞—Ç—å –ª–∏—à–Ω–∏–µ read –æ–ø–µ—Ä–∞—Ü–∏–∏
- [ ] –°–æ–∫—Ä–∞—Ç–∏—Ç—å thinking time –º–µ–∂–¥—É –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏

**–í–∞—Ä–∏–∞–Ω—Ç 3: –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥**
- [ ] Direct orchestrator –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á (—Å–æ–∑–¥–∞–Ω–∏–µ)
- [ ] Multi-agent –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö (—Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥, –≤–∞–ª–∏–¥–∞—Ü–∏—è)

### üìä –ö–∞–∫ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:

```bash
# 1. –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ master –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
git checkout master
npm run backend

# 2. –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ –∂–µ —Ç–µ—Å—Ç—ã
time curl -X POST http://localhost:3001/api/conversation \
  -H "Content-Type: application/json" \
  -d '{"message":"—Å–æ–∑–¥–∞–π —Å–∏–Ω–∏–π –∫—É–±","sessionId":"test_master_'$(date +%s)'"}'

# 3. –°—Ä–∞–≤–Ω–∏—Ç—å trace —Ñ–∞–π–ª—ã
cat logs/conversation-traces/conversation-*.json | jq '.metadata'

# 4. –í–µ—Ä–Ω—É—Ç—å—Å—è –Ω–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—É—é –≤–µ—Ç–∫—É
git checkout experiment/direct-orchestrator-no-subagents
```

---

## Project Overview

**VRCreator2** is an AI-powered Mixed Reality development platform combining IWSDK (Immersive Web SDK) with Claude Agent SDK for natural language-driven AR/VR object creation and manipulation. Files created in `src/generated/` appear as virtual 3D objects in the real world through device camera, with instant hot reload.

## Development Commands

```bash
# Install dependencies
npm install

# Start backend (Agent SDK orchestrator + TypeScript compiler + WebSocket server)
npm run backend          # Single run
npm run backend:watch    # Auto-restart on changes

# Start frontend (Vite dev server with IWSDK plugins)
npm run dev

# Build for production
npm run build

# Preview production build
npm run preview
```

## Environment Setup

Copy `.env.example` to `.env` and configure:
- `ANTHROPIC_API_KEY` - Required for Claude API access
- `VITE_GEMINI_API_KEY` - Required for voice input (speech-to-text)
- `MESHY_API_KEY` - Optional, for AI-powered 3D model generation
- Agent-specific model overrides (see `.env.example` for all options)

**Note:** Backend uses Claude Code OAuth by default. API key is only needed for legacy `/api/orchestrate` endpoint.

**Get API Keys:**
- Gemini API: https://aistudio.google.com/app/apikey (free tier: 15 requests/min)
- Claude API: https://console.anthropic.com/
- Meshy AI: https://www.meshy.ai/

## Architecture Overview

### Three-Layer System

1. **Frontend (IWSDK + WebSocket Client)**
   - `src/index.ts` - Entry point, initializes IWSDK World
   - `src/live-code/client.ts` - WebSocket client that receives compiled code
   - `src/generated/` - Live code files (git-ignored, auto-cleaned on hot reload)
   - Each file = independent module with isolated entity tracking

2. **Backend Agent System (Claude Agent SDK)**
   - `backend/src/orchestrator/conversation-orchestrator.ts` - Main coordinator
   - `backend/src/agents/` - Specialized sub-agents (code-generator, code-editor, validator, scene-manager)
   - `backend/src/services/session-store.ts` - SQLite-based conversation persistence
   - `backend/src/config/agents.ts` - Centralized agent configuration

3. **Hot Reload Pipeline**
   - `backend/src/websocket/file-watcher.ts` - Monitors `src/generated/` with chokidar
   - `backend/src/tools/typescript-checker.ts` - Compiles TS ‚Üí wrapped JS with hot reload tracking
   - `backend/src/websocket/live-code-server.ts` - WebSocket server (port 3002)

### Multi-Agent Architecture

The system uses **5 specialized agents** coordinated by a main orchestrator:

**Orchestrator** (`conversation-orchestrator.ts`)
- Maintains conversation with user
- Delegates tasks to sub-agents
- Has minimal tools (only `read_file` for rare direct file inspection)
- Relies on sub-agent context isolation to keep conversation context clean

**Sub-agents:**

1. **code-generator** - Creates new IWSDK code from scratch
   - Model: `sonnet` (configurable via `AGENT_CODE_GENERATOR_MODEL`)
   - Tools: `Read`, `Write`
   - Use when: Creating new components, objects, scenes

2. **code-editor** - Modifies existing code
   - Model: `sonnet` with lower temperature (0.5)
   - Tools: `Read`, `Edit`, `Write`
   - Use when: Bug fixes, refactoring, adding features to existing files

3. **validator** - Code quality review
   - Model: `haiku` (faster, cheaper)
   - Tools: `Read`, `Glob`, `Grep` (read-only)
   - Use when: Quality checks after major changes

4. **scene-manager** - Scene operations
   - Model: `haiku`
   - Tools: `Bash`, `Read`, `Write`, `Glob`
   - Use when: Clearing scene (`rm -rf src/generated/*`), deleting specific objects, save/load scenes

5. **3d-model-generator** - AI-powered 3D model generation via Meshy AI
   - Model: `sonnet` with higher temperature (0.8)
   - Tools: `generate_3d_model` (custom), `Read`, `Write`
   - Use when: Creating 3D models, characters, game assets

**Key Design Principle:** Sub-agents read files in their **isolated context**. Their file reads don't pollute the orchestrator's context, enabling long conversations without context overflow.

### API Endpoints

**Primary:**
- `POST /api/conversation` - Multi-agent conversation with session management (uses Claude Code OAuth)

**Legacy:**
- `POST /api/orchestrate` - Single-turn orchestrator (requires `ANTHROPIC_API_KEY`)

**Utilities:**
- `POST /api/execute` - Direct code execution without AI
- `GET /health` - Health check

### Hot Reload Mechanism

**How it works:**

1. File created/changed in `src/generated/` ‚Üí chokidar detects
2. TypeScript compiled with wrapper:
   ```typescript
   const moduleId = 'module-timestamp';
   window.__LIVE_MODULES__ = window.__LIVE_MODULES__ || {};
   window.__LIVE_MODULES__[moduleId] = { entities: [], cleanup: () => {...} };
   window.__trackEntity = (entity, mesh) => { /* tracks for cleanup */ };
   // ... user code ...
   ```
3. WebSocket sends compiled code to client
4. Client executes code (entities created in scene)
5. On file change/delete: cleanup old module ‚Üí execute new code

**Result:** Edit TypeScript file ‚Üí see changes in AR/VR instantly

### MCP Server (IWSDK Documentation)

The project includes an MCP server (`mcp-server/`) that provides IWSDK documentation to agents:

**Location:** `mcp-server/dist/index.js` (auto-configured in conversation orchestrator)

**Resources exposed:**
- `iwsdk://api/types-map` - Complete type definitions
- `iwsdk://api/ecs/overview` - Entity-Component-System architecture
- `iwsdk://api/grabbing/overview` - VR grabbing system
- `iwsdk://api/physics` - Physics components
- `iwsdk://api/spatial-ui/overview` - UI system

**Usage by agents:** Agents can use `mcp_read_resource` tool to fetch documentation before generating code.

### Conversation Tracing

All conversation traces are saved to `logs/conversation-traces/` as JSON files:

**Format:** `conversation-{timestamp}-{sessionId}.json`

**Contents:**
- `metadata`: requestId, sessionId, duration, agentsUsed, toolsUsed, filesCreated, filesModified
- `trace`: Array of all messages exchanged with Agent SDK (timestamped)

**Use for:** Debugging agent behavior, analyzing tool calls, understanding MCP interactions

### Session Management

Conversations persist across backend restarts via SQLite:

**Database:** `backend/data/sessions.db`

**Schema:**
- `sessions` table: sessionId, messages (JSON), metadata (JSON), lastActivity

**Usage:** Include `sessionId` in `/api/conversation` requests to continue previous conversation.

## IWSDK Code Patterns

### Minimal Working Example

```typescript
import { World } from '@iwsdk/core';
import * as THREE from 'three';

const world = window.__IWSDK_WORLD__ as World;

// Create geometry and material
const geometry = new THREE.BoxGeometry(0.5, 0.5, 0.5);
const material = new THREE.MeshStandardMaterial({ color: 0xff0000 });
const mesh = new THREE.Mesh(geometry, material);

// Set position BEFORE creating entity
mesh.position.set(0, 1.5, -2);

// Create entity from mesh
const entity = world.createTransformEntity(mesh);

// REQUIRED: Track for hot reload
(window as any).__trackEntity(entity, mesh);
```

### Making Objects Interactive

```typescript
import { Interactable, DistanceGrabbable } from '@iwsdk/core';

// Make interactable
entity.addComponent(Interactable);

// Make grabbable in VR (up to 10m away)
entity.addComponent(DistanceGrabbable, {
  maxDistance: 10
});
```

### Common Geometries

- `BoxGeometry(width, height, depth)` - Cubes/boxes
- `SphereGeometry(radius, widthSegments, heightSegments)` - Spheres
- `CylinderGeometry(radiusTop, radiusBottom, height, segments)` - Cylinders
- `PlaneGeometry(width, height)` - Flat planes
- `TorusGeometry(radius, tube, radialSegments, tubularSegments)` - Toruses

### Materials

**MeshStandardMaterial (PBR - use by default):**
```typescript
new THREE.MeshStandardMaterial({
  color: 0xff0000,     // Hex color
  roughness: 0.7,      // 0 = smooth, 1 = rough
  metalness: 0.3       // 0 = non-metal, 1 = metal
})
```

**MeshBasicMaterial (unlit):**
```typescript
new THREE.MeshBasicMaterial({ color: 0x00ff00 })
```

## Agent Configuration System

All agent behavior is configurable via environment variables (see `.env.example`).

### Model Selection Strategy

**Default assignments:**
- **code-generator, code-editor, 3d-model-generator**: `sonnet` (balance of quality/speed)
- **validator, scene-manager**: `haiku` (faster, cheaper for simple tasks)

**Override per agent:**
```bash
AGENT_CODE_GENERATOR_MODEL=opus    # Use most powerful model
AGENT_VALIDATOR_MODEL=haiku        # Use fastest/cheapest
```

### Extended Thinking (Beta)

Enable "thinking before responding" for complex tasks:

```bash
AGENT_CODE_GENERATOR_THINKING_ENABLED=true
AGENT_CODE_GENERATOR_THINKING_BUDGET=4000  # Must be ‚â•1024, <MAX_TOKENS
```

**When to enable:** Complex refactoring, architectural decisions, debugging subtle bugs

### Temperature Guidelines

- **0.3-0.5**: Precise, deterministic (editing, validation)
- **0.7**: Balanced creativity (code generation)
- **0.8-1.0**: Creative (3D prompts, novel solutions)

## File Structure

```
vrcreator2/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ generated/          # Live code files (git-ignored, hot reload)
‚îÇ   ‚îú‚îÄ‚îÄ live-code/          # WebSocket client & code executor
‚îÇ   ‚îî‚îÄ‚îÄ index.ts            # IWSDK initialization
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agents/         # 5 specialized AI agents
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ orchestrator/   # Main conversation coordinator
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/       # Session store (SQLite)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ websocket/      # File watcher + live code server
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tools/          # TypeScript compiler, custom tools
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/         # Agent configuration system
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ server.ts       # Express + WebSocket entry point
‚îÇ   ‚îî‚îÄ‚îÄ data/               # SQLite database
‚îú‚îÄ‚îÄ mcp-server/             # IWSDK documentation MCP server
‚îÇ   ‚îî‚îÄ‚îÄ dist/index.js       # Built MCP server
‚îú‚îÄ‚îÄ ui/                     # UIKitML UI definitions
‚îÇ   ‚îî‚îÄ‚îÄ welcome.uikitml     # Compiled to public/ui/welcome.json
‚îî‚îÄ‚îÄ logs/
    ‚îî‚îÄ‚îÄ conversation-traces/  # JSON trace files (debugging)
```

## Important Notes

### Security Constraints

Agents can **ONLY** write to:
- `src/generated/` - Live code objects
- `backend/generated/` - Backend generated code

**Cannot modify:**
- Core project files (`src/index.ts`, `vite.config.js`, etc.)
- `node_modules/`
- Configuration files
- Build artifacts

### Hot Reload Requirements

**Every file MUST include:**
```typescript
(window as any).__trackEntity(entity, mesh);
```

**Why:** Without this, entities won't be cleaned up on file changes, causing duplicate objects in scene.

### WebSocket Connection

Frontend connects to `ws://localhost:3002` (or `VITE_WS_URL` env var).

**Common issue:** If hot reload doesn't work, check:
1. Backend WebSocket server running on port 3002
2. Browser console for WebSocket connection errors
3. `backend/data/sessions.db` permissions

### TypeScript Compilation

TypeScript is compiled **on the backend** before sending to client:
- Type errors are logged but don't block execution (failover to original code)
- Source maps not included (compiled code is ephemeral)
- Imports are resolved relative to project root

## Debugging

### Conversation Traces

Check `logs/conversation-traces/` for full Agent SDK message history:

```bash
# View latest trace
cat logs/conversation-traces/conversation-*.json | jq '.metadata'

# See which agents were used
cat logs/conversation-traces/conversation-*.json | jq '.metadata.agentsUsed'

# Count messages exchanged
cat logs/conversation-traces/conversation-*.json | jq '.trace | length'
```

### Backend Logs

Backend uses `pino` structured logging:

```bash
# Watch logs with pretty printing
npm run backend:watch

# Filter for specific module
npm run backend 2>&1 | grep "conversation-orchestrator"

# Filter for MCP tool calls
npm run backend 2>&1 | grep "üîç MCP"
```

### Session Inspection

```bash
# View active sessions
sqlite3 backend/data/sessions.db "SELECT sessionId, lastActivity FROM sessions;"

# Clear all sessions
rm backend/data/sessions.db
```

## Testing the System

### Quick Test

```bash
# Start backend
npm run backend

# In another terminal, test conversation API
curl -X POST http://localhost:3001/api/conversation \
  -H "Content-Type: application/json" \
  -d '{"message":"–°–æ–∑–¥–∞–π —Ñ–∏–æ–ª–µ—Ç–æ–≤—ã–π –∫—É–± 0.5 –º–µ—Ç—Ä–∞","sessionId":"test-1"}'
```

**Expected:** JSON response with `success: true`, file created at `src/generated/*.ts`

### Verify Hot Reload

1. Start backend + frontend
2. Open frontend in browser (https://localhost:8081/)
3. Create file in `src/generated/test-cube.ts` (use IWSDK pattern above)
4. Check browser console: "‚úÖ Module loaded: module-..."
5. Edit file ‚Üí changes appear instantly in AR/VR view

### MCP Server Test

Agents should automatically access documentation via MCP:

```bash
# Check MCP server can start
node mcp-server/dist/index.js

# Monitor logs for MCP resource reads
npm run backend 2>&1 | grep "mcp_read_resource"
```

## Voice Input (Speech-to-Text)

VRCreator2 includes voice input powered by **Gemini Multimodal API** for hands-free interaction in VR.

### Features

- **Automatic Language Detection** - Supports 100+ languages (Russian, English, etc.) without manual configuration
- **Push-to-Talk Interface** - Hold button to record, release to transcribe
- **Quest Browser Compatible** - Works with `getUserMedia` WebM audio
- **Retry Mechanism** - Automatic fallback to alternative models on overload
- **Real-time Transcription** - Fast response time (typically 1-2 seconds)

### Architecture

**Frontend Components:**
- `src/services/gemini-audio-service.ts` - Voice recording and transcription service
- `src/config/gemini.ts` - API configuration and settings
- `src/panel.ts` - UI integration (MIC button handlers)

**Recording Flow:**
1. User presses MIC button ‚Üí `GeminiAudioService.start()`
2. Browser requests microphone permission
3. `MediaRecorder` captures audio in WebM format
4. User releases button ‚Üí `GeminiAudioService.stop()`
5. Audio converted to base64
6. Sent to Gemini API with transcription prompt
7. Transcribed text returned to UI

**API Details:**
- Endpoint: `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent`
- Format: Inline data with `audio/webm` mime type
- Prompt: "Transcribe this audio exactly. Return ONLY the transcribed text, no other commentary."
- Config: Low temperature (0.1) for accurate transcription

### Usage Example

```typescript
import { GeminiAudioService } from './services/gemini-audio-service';

const voiceService = new GeminiAudioService();

// Check if supported
if (!voiceService.isSupported()) {
  console.error('Microphone not supported');
  return;
}

// Push-to-Talk pattern
button.addEventListener('pointerdown', async () => {
  await voiceService.start(); // Start recording
  button.style.backgroundColor = 'red'; // Visual feedback
});

button.addEventListener('pointerup', async () => {
  button.style.backgroundColor = 'yellow'; // Processing

  const text = await voiceService.stop(); // Transcribe
  console.log('Transcribed:', text);

  button.style.backgroundColor = 'gray'; // Done
});
```

### Configuration

Required environment variable in `.env`:
```bash
VITE_GEMINI_API_KEY=your_api_key_here
GEMINI_MODEL=gemini-2.0-flash
```

Get your API key at: https://aistudio.google.com/app/apikey

**Rate Limits (Free Tier):**
- 15 requests per minute
- 1,500 requests per day
- 1 million tokens per day

### Error Handling

The service includes robust error handling:
- **Microphone denied** - Clear error message to user
- **API overload (503/429)** - Automatic retry with 2-second delay
- **Model unavailable** - Fallback to alternative model
- **Short recording** - Reject recordings under 100ms
- **Network errors** - Detailed error messages in console

### Browser Compatibility

| Browser | Recording | Transcription |
|---------|-----------|--------------|
| Chrome Desktop | ‚úÖ | ‚úÖ |
| Meta Quest Browser | ‚úÖ | ‚úÖ |
| Safari iOS | ‚ö†Ô∏è (requires user gesture) | ‚úÖ |
| Firefox | ‚úÖ | ‚úÖ |

**Note:** All browsers require **HTTPS** for `getUserMedia` (except localhost).

### Debugging

Enable verbose logging:
```typescript
// Console output shows:
// üé§ Recording started
// üöÄ Sending audio to gemini-2.0-flash (attempt 1/2)...
// ‚úÖ Transcription: "—Å–æ–∑–¥–∞–π –∫—Ä–∞—Å–Ω—ã–π –∫—É–±"
```

Check API key configuration:
```typescript
import { isGeminiConfigured } from './config/gemini';

if (!isGeminiConfigured()) {
  console.error('Gemini API key not set in .env');
}
```

### Cost Optimization

- Free tier covers most development and testing
- Each transcription request counts as ~1,000-2,000 tokens
- Approximate cost (paid tier): $0.001-0.002 per transcription
- Consider caching common phrases or commands

### Future Enhancements

- [ ] Add voice activity detection (stop on silence)
- [ ] Support custom wake words ("Hey VRCreator")
- [ ] Add local Whisper.cpp fallback for offline mode
- [ ] Implement streaming transcription for longer recordings
- [ ] Add voice commands for common actions
